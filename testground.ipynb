{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "general:\n",
      "  device: cuda\n",
      "  batch_size: 128\n",
      "  weight_decay: 0.0001\n",
      "  max_epochs: 50\n",
      "data:\n",
      "  dataset_root: D:\\Projekte\\GIA_220412_PCS\\02_Datasets\\FullWaveForm\\full_waveform_software\\FullWaveformParse_mass\\output\\FWF_Aachen_labeled\\\n",
      "  split: ./config/default_split.yaml\n",
      "  preprocessing:\n",
      "    _transformsTraining_:\n",
      "      xyz:\n",
      "        TransZRotation: {}\n",
      "        TransScaling: {}\n",
      "        TransGaussianNoise:\n",
      "          mean: 0\n",
      "          std: 0.002\n",
      "      rgb:\n",
      "        TransGaussianNoise:\n",
      "          mean: 0\n",
      "          std: 0.02\n",
      "        TransFeatureDropout:\n",
      "          dropout_prob: 0.1\n",
      "      wfm:\n",
      "        TransSignalScaling: {}\n",
      "      normals:\n",
      "        TransGaussianNoise:\n",
      "          mean: 0\n",
      "          std: 0.05\n",
      "      incAngles:\n",
      "        TransGaussianNoise:\n",
      "          mean: 0\n",
      "          std: 0.05\n",
      "        TransStandardize:\n",
      "          mean: 2.07\n",
      "          std: 0.38\n",
      "      distanceFromScanner:\n",
      "        TransGaussianNoise:\n",
      "          mean: 12.13\n",
      "          std: 12.2\n",
      "    _transformsValidation_:\n",
      "      xyz:\n",
      "        TransZRotation: {}\n",
      "        TransScaling: {}\n",
      "        TransGaussianNoise:\n",
      "          mean: 0\n",
      "          std: 0.002\n",
      "      rgb:\n",
      "        TransGaussianNoise:\n",
      "          mean: 0\n",
      "          std: 0.02\n",
      "        TransFeatureDropout:\n",
      "          dropout_prob: 0.1\n",
      "      wfm:\n",
      "        TransSignalScaling: {}\n",
      "      normals:\n",
      "        TransGaussianNoise:\n",
      "          mean: 0\n",
      "          std: 0.05\n",
      "      incAngles:\n",
      "        TransGaussianNoise:\n",
      "          mean: 0\n",
      "          std: 0.05\n",
      "        TransStandardize:\n",
      "          mean: 2.07\n",
      "          std: 0.38\n",
      "      distanceFromScanner:\n",
      "        TransGaussianNoise:\n",
      "          mean: 12.13\n",
      "          std: 12.2\n",
      "  scalar_input_fields:\n",
      "  - xyz\n",
      "  - rgb\n",
      "  - riegl_feats\n",
      "  - normals\n",
      "  - incAngles\n",
      "  - distanceFromScanner\n",
      "  fw_input_field: true\n",
      "  label_names:\n",
      "  - labels_0\n",
      "  query_grid_size: 0.15\n",
      "  subsample_on_gpu: true\n",
      "  num_neib_normalsComputation: 20\n",
      "  num_neib_featureExtraction: 128\n",
      "  _trainProjects_:\n",
      "  - proj_name: 2024-04-05_FW_Westbahnhof_02.FwfProj\n",
      "  _valProjects_:\n",
      "  - proj_name: 2023-08-28_FW_EingangBauing.FwfProj\n",
      "  label_schema:\n",
      "    labels_0:\n",
      "      scanArtefact: 0\n",
      "      manMade: 1\n",
      "      natural: 2\n",
      "    labels_1:\n",
      "      unspecified: 0\n",
      "      building: 1\n",
      "      sealedSurface: 2\n",
      "      streetFurniture: 3\n",
      "      vegetation: 4\n",
      "      vehicle: 5\n",
      "      naturalGround: 6\n",
      "      movingObject: 7\n",
      "    labels_2:\n",
      "      unspecified: 0\n",
      "      electricalAppliance: 1\n",
      "      facadeSurface: 2\n",
      "      pipeLike: 3\n",
      "      frameElement: 4\n",
      "      sign: 5\n",
      "      kerbStone: 6\n",
      "      nonTiledPaving: 7\n",
      "      shaft: 8\n",
      "      stair: 9\n",
      "      tiledPaving: 10\n",
      "      fence: 11\n",
      "      trashCan: 12\n",
      "      vegetation: 13\n",
      "      bicycle: 14\n",
      "      car: 15\n",
      "      scooter: 16\n",
      "      naturalGround: 17\n",
      "    labels_3:\n",
      "      unspecified: 0\n",
      "      metal: 1\n",
      "      naturalStone: 2\n",
      "      brick: 3\n",
      "      brick(graffiti): 4\n",
      "      concrete: 5\n",
      "      concrete(rough): 6\n",
      "      concrete(graffiti): 7\n",
      "      marking: 8\n",
      "      mesh: 9\n",
      "      plastic: 10\n",
      "      poster: 11\n",
      "      leaves: 12\n",
      "      asphalt: 13\n",
      "      cable: 14\n",
      "      grass: 15\n",
      "      soil: 16\n",
      "      treeTrunk: 17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from utils.pointcloud import BBox, grid_subsample_simple\n",
    "from data.fwf_dataset import FwfDataset\n",
    "from models.fgf import FGFeatNetwork\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "# build config\n",
    "cfg = OmegaConf.load(\"./config/default.yaml\")\n",
    "cfg = OmegaConf.merge(cfg, OmegaConf.load(cfg.data.split))\n",
    "with open(os.path.join(cfg.data.dataset_root, 'class_dict.json'),'r') as f:\n",
    "    cfg = OmegaConf.merge(cfg, OmegaConf.create({'data':{'label_schema':json.load(f)}}))\n",
    "\n",
    "\n",
    "print(OmegaConf.to_yaml(cfg))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading '2024-04-05_FW_Westbahnhof_02.FwfProj'; Bounding box IDs = default\n",
      "Loading '2023-08-28_FW_EingangBauing.FwfProj'; Bounding box IDs = default\n",
      "Computing neibors for '2024-04-05_FW_Westbahnhof_02.FwfProj::defaultBbox' @ k=20\n",
      "Computing normals for '2024-04-05_FW_Westbahnhof_02.FwfProj::defaultBbox' @ k=20\n",
      "Computing incidence angles for '2024-04-05_FW_Westbahnhof_02.FwfProj::defaultBbox'\n",
      "Computing neibors for '2024-04-05_FW_Westbahnhof_02.FwfProj::defaultBbox' @ k=128\n",
      "Computing neibors for '2023-08-28_FW_EingangBauing.FwfProj::defaultBbox' @ k=20\n",
      "Computing normals for '2023-08-28_FW_EingangBauing.FwfProj::defaultBbox' @ k=20\n",
      "Computing incidence angles for '2023-08-28_FW_EingangBauing.FwfProj::defaultBbox'\n",
      "Computing neibors for '2023-08-28_FW_EingangBauing.FwfProj::defaultBbox' @ k=128\n"
     ]
    }
   ],
   "source": [
    "train_ds = FwfDataset(cfg, cfg.data.preprocessing._transformsTraining_, cfg.data._trainProjects_)\n",
    "val_ds = FwfDataset(cfg, cfg.data.preprocessing._transformsValidation_, cfg.data._valProjects_)\n",
    "\n",
    "# rest computation\n",
    "for ds in [train_ds, val_ds]:\n",
    "    ds.compute_neibors_knn(k=cfg.data.num_neib_normalsComputation)\n",
    "    ds.compute_normals_knn()\n",
    "    ds.compute_incAngles()\n",
    "    ds.compute_neibors_knn(k=cfg.data.num_neib_featureExtraction)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# create model\n",
    "model = FGFeatNetwork(cfg=cfg,\n",
    "    num_input_feats = train_ds[0]['features_neibors'].shape[-1],\n",
    "    ).to(device=cfg.general.device)\n",
    "\n",
    "# create dataloader\n",
    "train_dl = DataLoader(train_ds, batch_size=cfg.general.batch_size)\n",
    "val_dl = DataLoader(val_ds, batch_size=cfg.general.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch-000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training       : 100%|██████████| 64/64 [00:05<00:00, 12.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                oA      mIoU        mP        mR      mF1     mcAcc\n",
      "labels_0  0.874434  0.292361  0.301548  0.328837  0.31278  0.328837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation     :  18%|█▊        | 627/3566 [00:37<02:55, 16.75it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     61\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i,batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(val_dl, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<15\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)):\n\u001b[0;32m     64\u001b[0m         \u001b[38;5;66;03m# put batch on device\u001b[39;00m\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     66\u001b[0m             batch[k] \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mgeneral\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\Hristo\\anaconda3\\lib\\site-packages\\tqdm\\std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Hristo\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Hristo\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Hristo\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Hristo\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\Projekte\\GIA_220412_PCS\\01_Code\\01_topic-01-sensitivity-analysis\\fg-feat-extractor\\data\\fwf_dataset.py:221\u001b[0m, in \u001b[0;36mFwfDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;66;03m# get neibors of point at index\u001b[39;00m\n\u001b[0;32m    217\u001b[0m neibs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprojects[proj_idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneibors\u001b[39m\u001b[38;5;124m'\u001b[39m][residual_idx]\n\u001b[0;32m    219\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m    220\u001b[0m     features_neibors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(\n\u001b[1;32m--> 221\u001b[0m         [\n\u001b[0;32m    222\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms_dict[f](\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprojects[proj_idx][f][neibs])\n\u001b[0;32m    223\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms_dict \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprojects[proj_idx][f][neibs]\n\u001b[0;32m    224\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mscalar_input_fields\n\u001b[0;32m    225\u001b[0m         ],\n\u001b[0;32m    226\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    227\u001b[0m     )\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[0;32m    228\u001b[0m     features_point \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(\n\u001b[0;32m    229\u001b[0m         [\n\u001b[0;32m    230\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms_dict[f](\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprojects[proj_idx][f][residual_idx][\u001b[38;5;28;01mNone\u001b[39;00m,:])\n\u001b[0;32m    231\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms_dict \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprojects[proj_idx][f][residual_idx][\u001b[38;5;28;01mNone\u001b[39;00m,:]\n\u001b[0;32m    232\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mscalar_input_fields\n\u001b[0;32m    233\u001b[0m         ],\n\u001b[0;32m    234\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    235\u001b[0m     )\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m    236\u001b[0m )\n\u001b[0;32m    238\u001b[0m \u001b[38;5;66;03m# add waveforms\u001b[39;00m\n\u001b[0;32m    239\u001b[0m return_dict\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m    240\u001b[0m     wfm_neibors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprojects[proj_idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwfm\u001b[39m\u001b[38;5;124m'\u001b[39m][neibs] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfw_input_field \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    241\u001b[0m     wfm_point \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprojects[proj_idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwfm\u001b[39m\u001b[38;5;124m'\u001b[39m][residual_idx][\u001b[38;5;28;01mNone\u001b[39;00m,:] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfw_input_field \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    242\u001b[0m )) \u001b[38;5;66;03m# type:ignore\u001b[39;00m\n",
      "File \u001b[1;32md:\\Projekte\\GIA_220412_PCS\\01_Code\\01_topic-01-sensitivity-analysis\\fg-feat-extractor\\data\\fwf_dataset.py:222\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;66;03m# get neibors of point at index\u001b[39;00m\n\u001b[0;32m    217\u001b[0m neibs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprojects[proj_idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneibors\u001b[39m\u001b[38;5;124m'\u001b[39m][residual_idx]\n\u001b[0;32m    219\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m    220\u001b[0m     features_neibors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(\n\u001b[0;32m    221\u001b[0m         [\n\u001b[1;32m--> 222\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransforms_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mf\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprojects\u001b[49m\u001b[43m[\u001b[49m\u001b[43mproj_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mf\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mneibs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms_dict \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprojects[proj_idx][f][neibs]\n\u001b[0;32m    224\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mscalar_input_fields\n\u001b[0;32m    225\u001b[0m         ],\n\u001b[0;32m    226\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    227\u001b[0m     )\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[0;32m    228\u001b[0m     features_point \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(\n\u001b[0;32m    229\u001b[0m         [\n\u001b[0;32m    230\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms_dict[f](\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprojects[proj_idx][f][residual_idx][\u001b[38;5;28;01mNone\u001b[39;00m,:])\n\u001b[0;32m    231\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms_dict \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprojects[proj_idx][f][residual_idx][\u001b[38;5;28;01mNone\u001b[39;00m,:]\n\u001b[0;32m    232\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mscalar_input_fields\n\u001b[0;32m    233\u001b[0m         ],\n\u001b[0;32m    234\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    235\u001b[0m     )\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m    236\u001b[0m )\n\u001b[0;32m    238\u001b[0m \u001b[38;5;66;03m# add waveforms\u001b[39;00m\n\u001b[0;32m    239\u001b[0m return_dict\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m    240\u001b[0m     wfm_neibors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprojects[proj_idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwfm\u001b[39m\u001b[38;5;124m'\u001b[39m][neibs] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfw_input_field \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    241\u001b[0m     wfm_point \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprojects[proj_idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwfm\u001b[39m\u001b[38;5;124m'\u001b[39m][residual_idx][\u001b[38;5;28;01mNone\u001b[39;00m,:] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfw_input_field \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    242\u001b[0m )) \u001b[38;5;66;03m# type:ignore\u001b[39;00m\n",
      "File \u001b[1;32md:\\Projekte\\GIA_220412_PCS\\01_Code\\01_topic-01-sensitivity-analysis\\fg-feat-extractor\\data\\transforms.py:103\u001b[0m, in \u001b[0;36mTransformsList.__call__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m--> 103\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32md:\\Projekte\\GIA_220412_PCS\\01_Code\\01_topic-01-sensitivity-analysis\\fg-feat-extractor\\data\\transforms.py:11\u001b[0m, in \u001b[0;36mTransform.__call__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Projekte\\GIA_220412_PCS\\01_Code\\01_topic-01-sensitivity-analysis\\fg-feat-extractor\\data\\transforms.py:55\u001b[0m, in \u001b[0;36mTransGaussianNoise.__init__.<locals>.fn\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(x:np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m---> 55\u001b[0m     noise \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m+\u001b[39m noise\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from utils.metrics import get_multilevel_metrics, print_metrics\n",
    "\n",
    "\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "optim = Adam(params=model.parameters(), weight_decay=cfg.general.weight_decay)\n",
    "\n",
    "for epoch in range(cfg.general.max_epochs):\n",
    "    print(f\"Epoch-{epoch:03}\")\n",
    "\n",
    "\n",
    "\n",
    "    # train\n",
    "    epoch_train_loss = []\n",
    "    epoch_predictions = {level:list() for level in cfg.data.label_names}\n",
    "    epoch_labels = {level:list() for level in cfg.data.label_names}\n",
    "    model.train()\n",
    "    for i, batch in enumerate(tqdm(train_dl, desc=f\"{'Training':<15}\", leave=True)):\n",
    "        optim.zero_grad()\n",
    "        # put batch on device\n",
    "        for k, v in batch.items():\n",
    "            batch[k] = v.to(device=cfg.general.device)\n",
    "\n",
    "        # forward pass\n",
    "        out = model(batch)\n",
    "        \n",
    "        # agregate loss on all levels\n",
    "        loss = torch.tensor(0.).to(device=cfg.general.device)\n",
    "        for k in out.keys():\n",
    "            output = out[k]\n",
    "            gt = batch[k] # type:ignore\n",
    "            loss += criterion(output, gt)\n",
    "        \n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "\n",
    "        # aggregate values for metric calculation\n",
    "        epoch_train_loss.append(loss.item())\n",
    "        for level in cfg.data.label_names:\n",
    "            epoch_predictions[level].append(torch.argmax(out[level],dim=1))\n",
    "            epoch_labels[level].append(batch[level])\n",
    "\n",
    "    # calculate_metrics\n",
    "    for level in cfg.data.label_names:\n",
    "        epoch_predictions[level] = torch.cat(epoch_predictions[level])\n",
    "        epoch_labels[level] = torch.cat(epoch_labels[level])\n",
    "\n",
    "    metrics = get_multilevel_metrics(epoch_predictions, epoch_labels, cfg)\n",
    "    print_metrics(metrics, cfg)\n",
    "\n",
    "    \n",
    "    # validate  \n",
    "    epoch_predictions = {level:list() for level in cfg.data.label_names}\n",
    "    epoch_labels = {level:list() for level in cfg.data.label_names}  \n",
    "    epoch_val_loss = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i,batch in enumerate(tqdm(val_dl, desc=f\"{'Validation':<15}\", leave=True)):\n",
    "            # put batch on device\n",
    "            for k, v in batch.items():\n",
    "                batch[k] = v.to(device=cfg.general.device)\n",
    "\n",
    "            # forward pass\n",
    "            out = model(batch)\n",
    "            \n",
    "            # agregate loss on all levels\n",
    "            loss = torch.tensor(0.).to(device=cfg.general.device)\n",
    "            for k in out.keys():\n",
    "                output = out[k]\n",
    "                gt = batch[k] # type:ignore\n",
    "                loss += criterion(output, gt)\n",
    "            \n",
    "            # aggregate values for metric calculation\n",
    "            epoch_val_loss.append(loss.item())\n",
    "            for level in cfg.data.label_names:\n",
    "                epoch_predictions[level].append(torch.argmax(out[level],dim=1))\n",
    "                epoch_labels[level].append(batch[level])\n",
    "\n",
    "        # calculate_metrics\n",
    "        for level in cfg.data.label_names:\n",
    "            epoch_predictions[level] = torch.cat(epoch_predictions[level])\n",
    "            epoch_labels[level] = torch.cat(epoch_labels[level])\n",
    "\n",
    "        metrics = get_multilevel_metrics(epoch_predictions, epoch_labels, cfg)\n",
    "        print_metrics(metrics, cfg)\n",
    "\n",
    "    print(f\"L_train:{np.mean(epoch_train_loss):.4f} L_val:{np.mean(epoch_val_loss):.4f}\")\n",
    "    print('\\n')\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmetrics\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([109, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['labels_0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels_0': tensor([1, 0, 2, 1, 2, 2, 2, 0, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2,\n",
       "         2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2,\n",
       "         2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 1, 2, 2,\n",
       "         2, 0, 0, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 0, 1, 0, 2, 2, 0, 1, 1, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2,\n",
       "         0, 0, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " 'labels_2': tensor([ 7,  7,  7,  7,  7,  7,  7,  7,  7,  7, 14,  7,  7,  7, 14,  7,  7,  7,\n",
       "          7,  7,  7,  7,  6,  7,  7,  7,  7, 10,  7,  7,  7,  7, 14,  7,  7,  7,\n",
       "          7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7, 14, 10,  7,\n",
       "          6,  7, 14,  7,  7,  7,  7,  7,  7,  7, 10,  7,  7,  7,  7,  7,  7,  7,\n",
       "          7,  7,  7,  7,  7,  7,  7,  7,  7,  7, 14, 10,  7,  7,  7,  7,  7,  7,\n",
       "          7,  7,  7,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7, 10,  7,  7,  7,  7,\n",
       "          7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  6,\n",
       "          7,  7], device='cuda:0')}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = {k:torch.argmax(v,dim=1) for k,v in out.items()}\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels_0': {'overall': {'overall_accuracy': 0.109375,\n",
       "   'confusion_matrix': array([[ 0.,  0.,  0.],\n",
       "          [15., 14., 99.],\n",
       "          [ 0.,  0.,  0.]], dtype=float32)},\n",
       "  'classwise': {'iou': array([0.      , 0.109375, 0.      ], dtype=float32),\n",
       "   'precision': array([0.        , 0.99999994, 0.        ], dtype=float32),\n",
       "   'recall': array([0.      , 0.109375, 0.      ], dtype=float32),\n",
       "   'f1_score': array([0.        , 0.19718291, 0.        ], dtype=float32),\n",
       "   'class_acc': array([0.      , 0.109375, 0.      ], dtype=float32)}},\n",
       " 'labels_2': {'overall': {'overall_accuracy': 0.0,\n",
       "   'confusion_matrix': array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "            0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "            0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  0.,  2., 55.,  0.,  0.,  3.,  0.,  0.,\n",
       "            0.,  4.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  0.,  2., 43.,  0.,  0.,  2.,  0.,  0.,\n",
       "            0.,  2.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "            0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  3.,  0.,  0.,  0.,  0.,  0.,\n",
       "            0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "            0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "            0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "            0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "            0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0., 12.,  0.,  0.,  0.,  0.,  0.,\n",
       "            0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "            0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "            0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "            0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "            0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "            0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "            0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "            0.,  0.,  0.,  0.,  0.]], dtype=float32)},\n",
       "  'classwise': {'iou': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0.], dtype=float32),\n",
       "   'precision': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0.], dtype=float32),\n",
       "   'recall': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0.], dtype=float32),\n",
       "   'f1_score': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0.], dtype=float32),\n",
       "   'class_acc': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0.], dtype=float32)}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.metrics import get_multilevel_metrics\n",
    "get_multilevel_metrics(preds,batch, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training       : 100%|██████████| 1804/1804 [19:05<00:00,  1.57it/s]\n",
    "# Validation     : 100%|██████████| 835/835 [07:57<00:00,  1.75it/s]\n",
    "# Epoch-000: Lt:0.4091 Lv:1.4503\n",
    "\n",
    "\n",
    "# Training       : 100%|██████████| 1804/1804 [19:28<00:00,  1.54it/s]\n",
    "# Validation     : 100%|██████████| 835/835 [07:31<00:00,  1.85it/s]\n",
    "# Epoch-001: Lt:0.3276 Lv:1.1352\n",
    "\n",
    "\n",
    "# Training       : 100%|██████████| 1804/1804 [19:20<00:00,  1.55it/s]\n",
    "# Validation     : 100%|██████████| 835/835 [07:06<00:00,  1.96it/s]\n",
    "# Epoch-002: Lt:0.2901 Lv:1.0932\n",
    "\n",
    "\n",
    "# Training       : 100%|██████████| 1804/1804 [19:16<00:00,  1.56it/s]\n",
    "# Validation     : 100%|██████████| 835/835 [06:57<00:00,  2.00it/s]\n",
    "# Epoch-003: Lt:0.2891 Lv:0.7242\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize normals\n",
    "# proj = train_ds.projects[7]\n",
    "for i, proj in enumerate(train_ds.projects):\n",
    "    PlyData([PlyElement.describe(pd.DataFrame(np.concatenate([proj['xyz'],proj['normals'],np.squeeze(proj['incAngles'])[:,None],np.proj['distanceFromScanner'][:,None], proj['sop_ids'][:,None]], axis=1),columns=['x','y','z','nx','ny','nz','incAngle','distanceFromScanner','sop_ids']).to_records(index=False),'vertex')]).write(f\"./_temp/proj_{i:03}.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for arr in [proj['xyz'],proj['normals'],np.squeeze(proj['incAngles'])[:,None],proj['distanceFromScanner'][:,None], proj['sop_ids'][:,None]]:\n",
    "    print(arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "train_ds[0]['features_neibors'].std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "train_ds[0]['features_neibors'].std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj['incAngles'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj['incAngles'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj['distanceFromScanner'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(proj['distanceFromScanner']-proj['distanceFromScanner'].mean()).std()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
